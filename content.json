{"pages":[{"title":"404","text":"var QZONE = window.QZONE || {}; function imagezoom(imgobj, box_w, box_h) { var src_w = imgobj.width; var src_h = imgobj.height; var r1 = src_w / src_h, r2 = box_w / box_h; var dst_w, dst_h; if (r1 > r2) { dst_w = box_w; dst_h = Math.round(dst_w / src_w * src_h); } else { if (r1 < r2) { dst_h = box_h; dst_w = Math.round(dst_h / src_h * src_w); } else { dst_w = box_w; dst_h = box_h; } } imgobj.style.marginLeft = (box_w - dst_w) / 2 + \"px\"; imgobj.style.marginTop = (box_h - dst_h) / 2 + \"px\"; imgobj.style.width = dst_w + \"px\"; imgobj.style.height = dst_h + \"px\"; imgobj.style.opacity = 1; } (function(_w, _d) { var ha = _d.head || _d.getElementsByTagName(\"head\")[0]; var $scope = {}; var current; var tmnow; var chId; var homePageUrl, homePageName; var scs = document.getElementsByTagName(\"script\"); if (location.href.indexOf(\"fm.qq.com\") > -1 || location.href.indexOf(\"fm.qzone.qq.com\") > -1) { homePageName = \"\\u8fd4\\u56de\\u4f01\\u9e45FM\"; homePageUrl = \"http://fm.qq.com\"; } else { if (location.href.indexOf(\"qzone.qq.com\") > -1) { homePageName = \"\\u8fd4\\u56de\\u6211\\u7684\\u7a7a\\u95f4\"; homePageUrl = \"http://qzone.qq.com\"; } else { homePageName = \"\\u8fd4\\u56de\\u817e\\u8baf\\u7f51\"; homePageUrl = \"http://www.qq.com\"; } } for (var i = 0;i < scs.length;i++) { if (scs[i].src.indexOf(\"404/search_children.js\") > -1) { if (scs[i].getAttribute(\"homePageUrl\")) { homePageUrl = scs[i].getAttribute(\"homePageUrl\"); } if (scs[i].getAttribute(\"homePageName\")) { homePageName = scs[i].getAttribute(\"homePageName\"); } break; } } $scope.rettext = homePageName; $scope.retlink = homePageUrl; function getData(srcUrl, callback) { var sc = _d.createElement(\"script\"); function orc() { if (sc.readyState === \"loaded\") { setTimeout(function() { callback && callback(); }, 0); } } if (sc.addEventListener) { if (callback) { sc.addEventListener(\"load\", callback, false); } } else { sc.attachEvent(\"onreadystatechange\", orc); } ha && ha.appendChild(sc); sc.src = srcUrl; } function resolveData(d) { var tid, len, ddata = [], tdata; if (\"object\" == typeof d && (d.data && (len = d.data.length))) { for (var i = 0;i < len;i++) { var expire = d.data[i].expire; d.data[i]._id = new Date * Math.random() * Math.random() * 1E7; if (expire && tmnow * 1E3 < Date.parse(expire.replace(/\\s[\\s\\S]*$/, \"\").replace(/\\-/g, \"/\"))) { var _c = d.data[i].city, _p = d.data[i].province; if (_c && city) { if ((\"_\" + _c + \"_\").indexOf(\"_\" + city + \"_\") > -1) { ddata.push(d.data[i]); continue; } } if (_p && province) { if ((\"_\" + _p + \"_\").indexOf(\"_\" + province + \"_\") > -1) { ddata.push(d.data[i]); } } } } tid = Math.floor(Math.random() * (ddata.length || len)); tdata = (ddata.length ? ddata : d.data)[chId = tid]; if (_w.foundjsondata) { tdata.ta = tdata.sex.indexOf(\"\\u5973\") > -1 ? \"\\u5979\" : \"\\u4ed6\"; tdata.name = \"\\u201c7\\u00b718\\u7279\\u5927\\u62d0\\u5356\\u5a74\\u513f\\u6848\\u201d\\u544a\\u7834\\uff0c\\u88ab\\u89e3\\u6551\\u768415\\u540d\\u5b69\\u5b50\\u4e2d\\uff0c2\\u4eba\\u7531\\u4eb2\\u751f\\u7236\\u6bcd\\u9886\\u56de\\uff0c\\u4ecd\\u670913\\u540d\\u5b69\\u5b50\\u672a\\u627e\\u5230\\u4eb2\\u751f\\u7236\\u6bcd\\uff0c\\u88ab\\u5b89\\u7f6e\\u5728\\u60e0\\u5dde\\u5e02\\u793e\\u4f1a\\u798f\\u5229\\u9662\\uff0c\" + tdata.ta + \"\\u662f\\u5176\\u4e2d\\u4e4b\\u4e00\\u3002\"; tdata.url = tdata.url.replace(/#p=(\\d{1,2})/, function(a, n) { return \"#p=\" + (+n + 1); }); return format(tmpl2, tdata); } if (!tdata.ext1) { tdata.ext1 = \"\\u4f46\\u6211\\u4eec\\u53ef\\u4ee5\\u4e00\\u8d77\\u5bfb\\u627e\\u5931\\u8e2a\\u5b9d\\u8d1d\"; } return tdata; } } function setTopData(tdata) { current = tdata; $scope.topname = tdata.name; $scope.topgender = tdata.sex; $scope.topbirth = tdata.birth_time; $scope.toplostdate = tdata.lost_time; $scope.toplostplace = tdata.lost_place; $scope.toplostdesc = tdata.child_feature; $scope.toplink = tdata.url; $scope.topimg = tdata.child_pic; $scope.topid = tdata._id; document.body.innerHTML = template(\"body\", $scope); } function init(data) { tmnow = data.tm_now * 1E3; var tdata = resolveData(jsondata); $scope.whichin = 0; jsondata.data.splice(chId, 1); $scope.otherdata = [tdata].concat(jsondata.data.slice(0, 5)); setTopData(tdata); } var timeout; window._Callback = function(d) { clearTimeout(timeout); init(d); }; timeout = setTimeout(function() { _Callback({tm_now:(new Date).getTime() / 1E3}); }, 2E3); _w.share = function(target) { var summary = [\"\\u80cc\\u666f\\uff1a\", current.name, \"\\uff0c\\u6027\\u522b\\uff1a\", current.sex, \"\\uff0c\\u51fa\\u751f\\u65f6\\u95f4\\uff1a\", current.birth_time, \"\\uff0c\\u5931\\u8e2a\\u65f6\\u95f4\\uff1a\", current.lost_time, \"\\uff0c\\u7279\\u5f81\\u63cf\\u8ff0\\uff1a\", current.child_feature].join(\"\"); if (summary) { summary = \"#\\u5bfb\\u627e\\u5931\\u8e2a\\u7684\\u5b9d\\u8d1d#\" + summary; } var stitle = \"\\u5931\\u8e2a\\u7684\\u5b9d\\u8d1d\\u8be6\\u60c5\"; var desc = \"\\u5931\\u8e2a\\u7684\\u5b9d\\u8d1d\\u8981\\u56de\\u5bb6\\uff0c\\u5feb\\u6765\\u53c2\\u4e0e\\u7231\\u5fc3\\u7684\\u4f20\\u9012\\u5427\\uff01\"; var encode = encodeURIComponent; var opts = {\"surl\":\"http://qzone.qq.com/gy/404/\" + current.id + \"/lostchild.html\", \"site\":\"QQ\\u7a7a\\u95f4\", \"summary\":summary || \"#\\u5b9d\\u8d1d\\u56de\\u5bb6#\\u817e\\u8baf\\u5fd7\\u613f\\u8005\\u7528\\u6280\\u672f\\u70b9\\u4eae\\u516c\\u76ca\\uff0c\\u8ba9\\u6211\\u4eec\\u4e00\\u8d77\\u5bfb\\u627e\\u8d70\\u5931\\u7684\\u513f\\u7ae5\\u5427\\uff01\", \"stitle\":stitle, \"pics\":current.child_pic, \"desc\":desc, \"origin_url\":current.url}; var surl = opts.surl || \"http://www.qq.com/404/\", summary = opts.summary || \"\\u8fd9\\u4e2a\\u662f\\u5206\\u4eab\\u7684\\u5185\\u5bb9\", stitle = opts.stitle || \"\\u8fd9\\u4e2a\\u662f\\u5206\\u4eab\\u7684\\u6807\\u9898\", pics = opts.pics || \"http://qzonestyle.gtimg.cn/qzone_v6/act/img/20120422_qzone_7_years/pop_up/icon-pop-seven-years.png\", site = opts.site || \"\\u8fd9\\u4e2a\\u662f\\u5206\\u4eab\\u94fe\\u63a5\\u7684\\u6587\\u5b57\", desc = opts.desc || \"\\u5931\\u8e2a\\u7684\\u5b9d\\u8d1d\\u8981\\u56de\\u5bb6\\uff0c\\u5feb\\u6765\\u53c2\\u4e0e\\u7231\\u5fc3\\u7684\\u4f20\\u9012\\u5427\\uff01\", origin_url = opts.origin_url || \"http://www.qq.com/404/\"; var shareList = {weibo:{method:function(evt) { var w = \"http://v.t.qq.com/share/share.php\", q = [\"?site=\", encode(surl + \"#via=share_t_weib\"), \"&title=\", encode(summary), \"&pic=\", encode(pics), \"&url=\", encode(surl)].join(\"\"), p = [w, q].join(\"\"); openit(p, \"weibo\", \"width=700, height=680, top=0, left=0, toolbar=no, menubar=no, scrollbars=no, location=yes, resizable=no, status=no\"); }}, qzone:{method:function(evt) { var buff = [], ps = {url:surl + \"#via=404-qzoneshare\", desc:desc || \"\\u5931\\u8e2a\\u7684\\u5b9d\\u8d1d\\u8981\\u56de\\u5bb6\\uff0c\\u5feb\\u6765\\u53c2\\u4e0e\\u7231\\u5fc3\\u7684\\u4f20\\u9012\\u5427\\uff01\", summary:summary, title:stitle, pics:pics, site:site}; for (var k in ps) { buff.push(k + \"=\" + encode(ps[k] || \"\")); } var w = \"http://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?\" + buff.join(\"&\"), q = [\"#via=share_t_qzone\", \"&title=\", encode(summary), \"&pic=\", encode(pics), \"&url=\", encode(surl)].join(\"\"), p = [w, q].join(\"\"); openit(p, \"qzone\", \"width=700, height=680, top=0, left=0, toolbar=no, menubar=no, scrollbars=no, location=yes, resizable=no, status=no\"); }}, sina:{method:function() { var w = \"http://v.t.sina.com.cn/share/share.php\", q = [\"?url=\", encode(surl + \"#via=share_x_weib\"), \"&title=\", encode(summary), \"&source=\", \"&sourceUrl=\", surl, \"&content=utf-8\", \"&pic=\", encode(pics)].join(\"\"), p = [w, q].join(\"\"); openit(p, \"sina\", \"toolbar=0,status=0,resizable=1,width=440,height=430\"); }}, kaixin:{method:function() { var n = \"http://www.kaixin001.com/repaste/bshare.php?rurl=\" + encode(surl + \"#via=share_kaixin\") + \"&rcontent=&rtitle=\" + encode(summary); openit(n, \"kaixin\", \"toolbar=0,status=0,resizable=1,width=600,height=360\"); }}, renren:{method:function() { var n = \"http://www.connect.renren.com/share/sharer?title=\" + encode(summary) + \"&url=\" + encode(surl + \"#via=share_renren\"), p = window.open(n, \"rr\", \"toolbar=0,status=0,resizable=1,width=510,height=300\"); if (p) { p.focus(); } }}, weixin:{method:function() { var n = \"http://qzone.qq.com/gy/404/page/qrcode.html?url=\" + encode(origin_url + \"#via=share_weixin\"), p = window.open(n, \"rr\", \"toolbar=0,status=0,resizable=1,width=620,height=430\"); if (p) { p.focus(); } }}}; var openit = function(u, n, p) { function o() { var z; if (!(z = window.open(u, n, p))) { location.href = u; } else { z.focus(); } } o(); }; shareList[target] && shareList[target].method(); }; _w.toThis = function(id) { for (var i = 0;i < $scope.otherdata.length;i++) { if ($scope.otherdata[i]._id == id) { setTopData($scope.otherdata[i]); break; } } return false; }; var meta = document.createElement(\"meta\"); meta.name = \"viewport\"; meta.content = \"width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no\"; ha.appendChild(meta); (function registerStyle() { var link = document.createElement(\"link\"); link.rel = \"stylesheet\"; link.type = \"text/css\"; link.href = \"https://qzone.qq.com/gy/404/style/404style.css\"; ha.appendChild(link); })(); (function initStat() { var qqDomainNameRE = /\\.qq\\.com$/i, qzoneDomainNameRE = /\\bqzone\\.qq\\.com$/i, qzsDomainNameRE = /\\bqzonestyle\\.gtimg\\.cn$/i; function cb() { var url = location.host; var src = \"\"; if (qzoneDomainNameRE.test(url)) { src = \"new404.qzone\"; } else { if (qqDomainNameRE.test(url)) { src = \"new404.qq\"; } else { if (qzsDomainNameRE.test(url)) { src = \"new404.qzonestyle\"; } else { src = url.replace(\".\", \"_\"); } } } _w.TCISD && (_w.TCISD.pv && _w.TCISD.pv(\"hat.qzone.qq.com\", \"/gy/lostchild/\" + src)); } getData(\"https://qzonestyle.gtimg.cn/ac/qzfl/stat.js\", cb); })(); })(window, document); !function() { function a(a, b) { return(/string|function/.test(typeof b) ? h : g)(a, b); } function b(a, c) { return \"string\" != typeof a && (c = typeof a, \"number\" === c ? a += \"\" : a = \"function\" === c ? b(a.call(a)) : \"\"), a; } function c(a) { return l[a]; } function d(a) { return b(a).replace(/&(?![\\w#]+;)|[\"']/g, c); } function e(a, b) { if (m(a)) { for (var c = 0, d = a.length;d > c;c++) { b.call(a, a[c], c, a); } } else { for (c in a) { b.call(a, a[c], c); } } } function f(a, b) { var c = /(\\/)[^/]+\\1\\.\\.\\1/, d = (\"./\" + a).replace(/[^/]+$/, \"\"), e = d + b; for (e = e.replace(/\\/\\.\\//g, \"/\");e.match(c);) { e = e.replace(c, \"/\"); } return e; } function g(b, c) { var d = a.get(b) || i({filename:b, name:\"Render Error\", message:\"Template not found\"}); return c ? d(c) : d; } function h(a, b) { if (\"string\" == typeof b) { var c = b; b = function() { return new k(c); }; } var d = j[a] = function(c) { try { return new b(c, a) + \"\"; } catch (d) { return i(d)(); } }; return d.prototype = b.prototype = n, d.toString = function() { return b + \"\"; }, d; } function i(a) { var b = \"{Template Error}\", c = a.stack || \"\"; if (c) { c = c.split(\"\\n\").slice(0, 2).join(\"\\n\"); } else { for (var d in a) { c += \"\\n\" + a[d] + \"\\n\\n\"; } } return function() { return \"object\" == typeof console && console.error(b + \"\\n\\n\" + c), b; }; } var j = a.cache = {}, k = this.String, l = {\"\":\">\", '\"':\"\"\", \"'\":\"'\", \"&\":\"&\"}, m = Array.isArray || function(a) { return \"[object Array]\" === {}.toString.call(a); }, n = a.utils = {$helpers:{}, $include:function(a, b, c) { return a = f(c, a), g(a, b); }, $string:b, $escape:d, $each:e}, o = a.helpers = n.$helpers; a.get = function(a) { return j[a.replace(/^\\.\\//, \"\")]; }, a.helper = function(a, b) { o[a] = b; }, \"function\" == typeof define ? define(function() { return a; }) : \"undefined\" != typeof exports ? module.exports = a : this.template = a, a(\"body\", function(a) { var b = this, c = (b.$helpers, b.$escape), d = a.retlink, e = a.rettext, f = a.topid, g = a.topimg, h = a.topname, i = a.topgender, j = a.topbirth, l = a.toplostdate, m = a.toplostplace, n = a.toplostdesc, o = a.toplink, p = b.$each, q = a.otherdata, r = (a.otheritem, a.index, \"\"); return r += ' 404\\uff0c\\u60a8\\u8bbf\\u95ee\\u7684\\u9875\\u9762\\u627e\\u4e0d\\u56de\\u6765\\u4e86\\uff0c\\u4f46\\u6211\\u4eec\\u53ef\\u4ee5\\u4e00\\u8d77\\u5e2e\\u4ed6\\u4eec\\u56de\\u5bb6\\uff01 ', r += c(e), r += ' ', r += c(h), r += '(', r += c(i), r += ') \\u51fa\\u751f\\u65e5\\u671f\\uff1a', r += c(j), r += ' \\u5931\\u8e2a\\u65f6\\u95f4\\uff1a', r += c(l), r += ' \\u5931\\u8e2a\\u5730\\u70b9\\uff1a', r += c(m), r += ' \\u5931\\u8e2a\\u4eba\\u7279\\u5f81\\u63cf\\u8ff0\\uff1a', r += c(n), r += ' \\u67e5\\u770b\\u8be6\\u60c5 \\u5206\\u4eab \\u817e\\u8baf\\u5fae\\u535a QQ\\u7a7a\\u95f4 \\u65b0\\u6d6a\\u5fae\\u535a \\u5fae\\u4fe1 ', p(q, function(a) { r += ' '; }), r += \" \", new k(r); }); }();","link":"/404.html"},{"title":"","text":"个人简介 分享很喜欢的老罗的一段话： “每一个生命来到世间都注定改变世界，别无选择。要么变得好一点，要么变得坏一点。你如果走进社会为了生存为了什么不要脸的理由，变成了一个恶心的成年人社会中的一员，那你就把这个世界变得恶心了一点点。如果你一生刚正不阿，如果你一生耿直，没有做任何恶心的事情，没做对别人有害的事情，一辈子拼了老命勉强把自己身边的几个人照顾好了，没有成名没有发财，没有成就伟大的事业，然后耿着脖子一生正直，到了七八十岁耿着脖子去世了。你这一生是不是没有改变世界？你还是改变世界了，你把这个世界变得美好了一点点。因为世界上又多了一个好人。“ 善恶终有报,天道好轮回。不信抬头看,苍天饶过谁。无论何时何地，我们都要保持一颗积极乐观、善良感恩的心。但行好事莫问前程，永远年轻，永远热内盈眶，永远保持正能量。💪💪💪💪💪💪冲鸭！！！！ -&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;个人信息：计算机科学与技术专业从事JAVA后端开发码畜一枚坚信代码改变世界 博客信息 网站采用的Icarus主题 追求尽可能的简洁，清晰，易用。 在Icarus主题之上进行了部分修改。 更新日志：–2020.09.20：icarus4.0适配–2020.01.18：icarus3.0适配–2019.11.17：增加深色主题开关–2019.10.30：去图，精简卡片–2019.10.22：改版部分显示，优化速度–2019.10.16：文章列表加上评论数显示–2019.10.13：改版评论–2019.09.25：图片、资源接入CDN免费jsDelivr、文章加入置顶–2019.09.19：开源博客代码–2019.09.19：修改布局，拉伸布局，更宽的展示–2019.09.18：修改友链ui为一行三个，并适配移动端，暗黑模式文章增加评论链接，增加留言链接–2019.09.14：增加精简next主题–2019.09.14：利用中秋节放假，重做了首页的热门推荐、加个widget最新评论框、归档页加入文章贡献概览面板 本站推荐索引 博客主题相关 github Issue 作为博客微型数据库的应用 github page网站cdn优化加速 博客源码分享 博客换肤的一种实现方式思路 博客中gitalk最新评论的获取 博客图片上传picgo工具github图传使用 安装、部分配置icarus主题中文版 技术知识点 Java并发知识点 法律法规 法律法规数据库 中华人民共和国国旗法 中华人民共和国宪法 中华人民共和国消费者权益保护法 中华人民共和国刑事诉讼法 中华人民共和国婚姻法 中华人名共和国网络安全法 中华人民共和国劳动法 其他 网易云音乐歌单分享 计划2020计划 2019.12.31 2020-GOALS 跑两三场马拉松 2019计划 2018.12.31/21:59:00-&gt;更新于2019.12.31 2019-GOALS 购买的专业书籍至少看完一遍（并发、重构、设计模式…）-&gt; 95% 额外： 追了很多剧 总结： 有优点有缺点，没坚持下来的还是太多，追了太多剧。以后多学习，多思考！ 时间轴记录","link":"/about/index.html"},{"title":"","text":"🎈🎈微笑墙🎈🎈 彭小苒 唐艺昕 李一桐 gakki 图片搜集于互联网，侵权请留言，马上处理😊。","link":"/album/index.html"},{"title":"","text":"申请友链须知 原则上只和技术类博客交换，但不包括含有和色情、暴力、政治敏感的网站。 不和剽窃、侵权、无诚信的网站交换，优先和具有原创作品的网站交换。 申请请提供：站点名称、站点链接、站点描述、logo或头像（不要设置防盗链）。 排名不分先后，刷新后重排，更新信息后请留言告知。 会定期清理很久很久不更新的、不符合要求的友链，不再另行通知。 本站不存储友链图片，如果友链图片换了无法更新。图片裂了的会替换成默认图，需要更换的请留言告知。 本站友链信息如下，申请友链前请先添加本站信息： 网站图标：https://removeif.github.io/images/avatar.jpg 网站名称：辣椒の酱 网站地址：https://removeif.github.io 网站简介：后端开发，技术分享 加载中，稍等几秒...","link":"/friend/index.html"},{"title":"","text":"&nbsp;&nbsp;听听音乐 音乐播放器由mePlayer提供，布局参照网友博客所作，感谢作者的辛勤付出。更多音乐分享请查看歌单。 &nbsp;&nbsp;看看视频 ->点击以下条目开始播放视频,向下滑动查看更多","link":"/media/index.html"},{"title":"","text":"来而不往非礼也畅所欲言，有留必应","link":"/message/index.html"},{"title":"音乐歌单收藏","text":"温馨提示：选择喜欢的音乐双击播放，由于版权原因部分不能播放。如果喜欢歌单收藏一下，去网易云都能播放哟！","link":"/music/index.html"},{"title":"","text":"碎碎念 tips：github登录后按时间正序查看、可点赞加❤️、本插件地址..「+99次查看」 碎碎念加载中，请稍等... $.getScript(\"/js/gitalk_self.min.js\", function () { var gitalk = new Gitalk({ clientID: '46a9f3481b46ea0129d8', clientSecret: '79c7c9cb847e141757d7864453bcbf89f0655b24', id: '666666', repo: 'issue_database', owner: 'removeif', admin: \"removeif\", createIssueManually: true, distractionFreeMode: false }); gitalk.render('comment-container1'); });","link":"/self-talking/index.html"}],"posts":[{"title":"Kafka消费指定时间段消息","text":"通过时间戳找到每个分区对应的位点，消费每个分区两个位点之间的消息。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758class KafkaConsumerFromTimestamp: def __init__(self): self.consumer = KafkaConsumer(bootstrap_servers=kafkaConfig['host'], api_version=(0, 10, 2), session_timeout_ms=25000, max_poll_records=1000, fetch_max_bytes=1 * 1024 * 1024) self.consumer.subscribe([input['topic']]) self.endOffsetDict = {} self.parSet = set() self.getData() def getOffsets(self): self.consumer.poll(timeout_ms=100, max_records=100, update_offsets=True) assignment = self.consumer.assignment() startTime = int(time.time() - 61) * 1000 # 1 mins ago timestamp endTime = int(time.time() - 1) * 1000 # current timestamp # start timestamp timestampToSearch = {} partitionList = [] for tp in assignment: timestampToSearch[tp] = startTime partitionList.append(tp) startOffsets = self.consumer.offsets_for_times(timestampToSearch) # end timestamp timestampToSearch = {} partitionList = [] for tp in assignment: timestampToSearch[tp] = endTime partitionList.append(tp) endOffsets = self.consumer.offsets_for_times(timestampToSearch) # add endoffsets in dict for TopicPartition, OffsetAndTimestamp in endOffsets.items(): self.endOffsetDict['partition_' + str(TopicPartition.partition)] = OffsetAndTimestamp.offset # seek start point for tp in assignment: offsetAndTimestamp = startOffsets[tp] if offsetAndTimestamp is not None: self.consumer.seek(tp, offsetAndTimestamp.offset) def getData(self): self.getOffsets() for msg in self.consumer: msgOffset = msg.offset msgPartition = msg.partition # all partitions traversed then break if len(self.parSet) == 12: break # each partition traversed then continue if msgOffset &gt; self.endOffsetDict['partition_' + str(msgPartition)]: self.parSet.add(msgPartition) continue val = json.loads(msg.value) print(val) 并不是所有的offset或timestamp都有消息，如何找到合适的offset或time？ 先seekToEnd，再获得position，也就是此时的offset。 12self.consumer.seek_to_end(partition)self.consumer.position(partition) 用consumer.endOffsets(partitions).get(TopicPartition) 12self.partition = TopicPartition(topic=myTopic, partition=myPartition)self.endingOffset = self.consumer.end_offsets(self.partition) 同理，也有beginningOffsets() 如果有多个topic partition，可以用一个HashSet。","link":"/2022/01/18/Kafka%E6%B6%88%E8%B4%B9%E6%8C%87%E5%AE%9A%E6%97%B6%E9%97%B4%E6%AE%B5%E6%B6%88%E6%81%AF/"},{"title":"Linux crontab 命令","text":"Linux crontab是用来定期执行程序的命令。 当安装完成操作系统之后，默认便会启动此任务调度命令。 crond 命令每分锺会定期检查是否有要执行的工作，如果有要执行的工作便会自动执行该工作。 注意：新创建的 cron 任务，不会马上执行，至少要过 2 分钟后才可以，当然你可以重启 cron 来马上执行。 Crontab 重启命令12# --重启命令--/etc/init.d/cron restart 查看Crontab是否启动1sudo launchctl list | grep cron 编辑Crontab内容1crontab -e Crontab 文件格式 格式 第1列：分钟，0～59 第2列：小时，0～23 第3列：日期，1～31 第4列：月份，1～12 第5列：星期，0～7（0和7表示星期天） 第6列：要运行的命令（如果有多个命令用 &amp;&amp; 隔开） 特殊字符 星号**(*)** ：代表所有可能的值，例如，month字段如果是星号，则表示在满足其它字段的制约条件后，每月都执行该命令操作； 逗号**(,)** ：可以用逗号隔开的值，指定一个多元素的列表，例如：1,2,5,7,8,9 中杠**(-)** ：可以用整数之间的中杠表示一个整数范围，例如“2-6”表示：2,3,4,5,6 正斜线**(/)** ：可以用正斜线指定时间的间隔频率，例如“0-23/2”表示每两小时执行一次。同时正斜线可以和星号一起使用，例如*/10，如果用在minute字段，表示每十分钟执行一次。 示例 每1分钟执行一次 1*/1 * * * * 每隔两天的上午8点到11点的第3和第15分钟执行 13,15 8-11 */2 * * 每个星期一的上午8点到11点的第3和第15分钟执行 13,15 8-11 * * 1 每月的4号与每周一到周三的11点重启smb 10 11 4 * mon-wed /etc/init.d/smb restart 每小时执行/etc/cron.hourly目录内的脚本 101 * * * * root run-parts /etc/cron.hourly 说明：run-parts这个参数，如果去掉这个参数的话，后面就可以写要运行的某个脚本名，而不是目录名了。 路径问题 单独执行定时任务时候没有问题，单独执行python脚本没有问题，此定时任务不执行原因是因为python路径要写绝对路径 首先在linux上执行命令：where is python3.8 或者 which python3.8，得到python的绝对路径 12which python3.8/usr/local/bin/python3.8 设定执行任务 130 8 * * * /usr/local/bin/python3.8 /user/loacl/bin/***/***.py","link":"/2022/01/14/Linux-crontab-%E5%91%BD%E4%BB%A4/"},{"title":"Mysql导入导出数据","text":"导入Excel：准备.txt文件 将要导入的数据（不含表头）从工作表复制、粘贴到一个新建的Excel数据表中（避免污染源数据） 粘贴时注意：使用右键paste as value选项，过滤掉源数据表中的多余格式（如，字体颜色、粗体等） 将新建的Excel文档（只含一张数据表）另存为unicode文本（试过.csv格式，不好用） 关闭另存为后的Excel文档，在资源管理器中用记事本打开该文档，点击“另存为“按钮，发现编码格式为“Unicode”，将此项更改为“UTF-8”，覆盖源文件。（这一步很关键，如果缺少，则在导入.txt文件时Mysql会报出让人费解的错误：invalid utf8 character string ‘’） 建表、导入.txt文件 根据Excel数据表的结构，设计Mysql表结构（感觉Text格式比varchar好用，不用关心各字段的长度问题） 创建表：Create table term (type text, subtype text, en text, cn text, chd text) character set=utf8; 使用Load Data InFile ‘D:/sample.txt’ Into Table terms lines terminated by ‘\\r\\n’;语句导入.txt，成功！ 导出Excel：1SELECT * into outfile '/Users/panxiao/Desktop/Export/region.xlsx' FROM region; Maxcompute tunnel 导入 Import as .csv file(partition by ,) then save as txt encoding with utf-8 Tunnel upload /Users/panxiao/Desktop/xxx.txt table_name","link":"/2022/01/07/Mysql%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BA%E6%95%B0%E6%8D%AE/"},{"title":"Python 获取目录","text":"Python 获取当前目录, 上级目录, 上上级目录123456789101112131415# --run--import osprint '***获取当前目录***'print os.getcwd()print os.path.abspath(os.path.dirname(__file__))print '***获取上级目录***'print os.path.abspath(os.path.dirname(os.path.dirname(__file__)))print os.path.abspath(os.path.dirname(os.getcwd()))print os.path.abspath(os.path.join(os.getcwd(), &quot;..&quot;))print os.path.abspath('.')print '***获取上上级目录***'print os.path.abspath(os.path.join(os.getcwd(), &quot;../..&quot;))","link":"/2022/01/07/Python-%E8%8E%B7%E5%8F%96%E5%BD%93%E5%89%8D%E7%9B%AE%E5%BD%95-%E4%B8%8A%E7%BA%A7%E7%9B%AE%E5%BD%95-%E4%B8%8A%E4%B8%8A%E7%BA%A7%E7%9B%AE%E5%BD%95/"},{"title":"Python多线程与多线程中join()的用法","text":"Python多线程与多进程中join()方法的效果是相同的。 首先需要明确几个概念： 一、 当一个进程启动之后，会默认产生一个主线程，因为线程是程序执行流的最小单元，当设置多线程时，主线程会创建多个子线程，在python中，默认情况下（其实就是setDaemon(False)），主线程执行完自己的任务以后，就退出了，此时子线程会继续执行自己的任务，直到自己的任务结束。123456789101112131415161718192021222324import threadingimport timedef run(): time.sleep(2) print('当前线程的名字是： ', threading.current_thread().name) time.sleep(2)if __name__ == '__main__': start_time = time.time() print('这是主线程：', threading.current_thread().name) thread_list = [] for i in range(5): t = threading.Thread(target=run) thread_list.append(t) for t in thread_list: t.start() print('主线程结束！' , threading.current_thread().name) print('一共用时：', time.time()-start_time) 其执行结果如下: 12345678910这是主线程: MainThread主线程结束了！ MainThread一共用时: 0.0010004043579101562当前线程的名字是: Thread-1当前线程的名字是: Thread-5当前线程的名字是: Thread-4当前线程的名字是: Thread-3当前线程的名字是: Thread-2Process finished with exit code 0 关键点: 我们的计时是对主线程计时，主线程结束，计时随之结束，打印出主线程的用时。 主线程的任务完成之后，主线程随之结束，子线程继续执行自己的任务，直到全部的子线程的任务全部结束，程序结束。 二、 当我们使用setDaemon(True)方法，设置子线程为守护线程时，主线程一旦执行结束，则全部线程全部被终止执行，可能出现的情况就是，子线程的任务还没有完全执行结束，就被迫停止。1234567891011121314151617181920212223242526import threadingimport timedef run(): time.sleep(2) print('当前线程的名字是： ', threading.current_thread().name) time.sleep(2)if __name__ == '__main__': start_time = time.time() print('这是主线程：', threading.current_thread().name) thread_list = [] for i in range(5): t = threading.Thread(target=run) thread_list.append(t) for t in thread_list: t.setDaemon(True) t.start() print('主线程结束了！' , threading.current_thread().name) print('一共用时：', time.time()-start_time) 其执行结果如下，注意请确保setDaemon()在start()之前。 12345这是主线程: MainThread主线程结束了! mainThread一共用时: 0.0010006427764892578Process finished with exit code 0 关键点： 非常明显的看到，主线程结束以后，子线程还没有来得及执行，整个程序就退出了。 三、 此时join的作用就凸显出来了，join所完成的工作就是线程同步，即主线程任务结束之后，进入阻塞状态，一直等待其他的子线程执行结束之后，主线程在终止。1234567891011121314151617181920212223242526272829import threadingimport timedef run(): time.sleep(2) print('当前线程的名字是： ', threading.current_thread().name) time.sleep(2)if __name__ == '__main__': start_time = time.time() print('这是主线程：', threading.current_thread().name) thread_list = [] for i in range(5): t = threading.Thread(target=run) thread_list.append(t) for t in thread_list: t.setDaemon(True) t.start() for t in thread_list: t.join() print('主线程结束了！' , threading.current_thread().name) print('一共用时：', time.time()-start_time) 其执行结果如下： 12345678910这是主线程: MainThread当前线程的名字是: Thread-2当前线程的名字是: Thread-1当前线程的名字是: Thread-3当前线程的名字是: Thread-5当前线程的名字是: Thread-4主线程结束了! MainThread一共用时: 4.002500057220459Process finished with exit code 0 关键点： 可以看到，主线程一直等待全部的子线程结束之后，主线程自身才结束，程序退出。 四、 join有一个timeout参数： 当设置守护线程时，含义是主线程对于子线程等待timeout的时间将会杀死该子线程，最后退出程序。所以说，如果有10个子线程，全部的等待时间就是每个timeout的累加和。简单的来说，就是给每个子线程一个timeout的时间，让他去执行，时间一到，不管任务有没有完成，直接杀死。 没有设置守护线程时，主线程将会等待timeout的累加和这样的一段时间，时间一到，主线程结束，但是并没有杀死子线程，子线程依然可以继续执行，直到子线程全部结束，程序退出。","link":"/2022/01/19/Python%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%ADjoin-%E7%9A%84%E7%94%A8%E6%B3%95/"},{"title":"PaddleOCR接口设计","text":"ocr.py1234567891011121314from paddleocr import PaddleOCRfrom recognition import Recongnitionclass ocr: def __init__(self): self.ocr = PaddleOCR(use_angle_cls=True, use_gpu=False, lang='ch', cls_model_dir='./PaddleOCR/inference/ch_ppocr_mobile_v2.0_cls_infer', det_model_dir='./PaddleOCR/inference/ch_ppocr_mobile_v2.0_det_infer', rec_model_dir='./PaddleOCR/inference/ch_ppocr_mobile_v2.0_rec_infer', rec_char_dict_path='./PaddleOCR/ppocr/utils/ppocr_keys_v1.txt') def run(self, imgsrc): rec = Recongnition(imgsrc, self.ocr) return rec.ImagRecognition() recognition.py123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101from PIL import Imageclass Recongnition: def __init__(self, imgsrc, ocr): self.imgsrc = imgsrc self.ocr = ocr self.date = time.strftime(&quot;%Y%m%d&quot;, time.localtime()) # 分辨率统一转换成1080p def transfer(self, file): img = Image.open(file) size = img.size if size[0] != 1080 and size[1] != 1920: reim = img.resize((1080, 1920)) reim.save(file) # 图片剪裁 def cutImg(self, coordinate, imagPath): &quot;&quot;&quot;根据坐标位置剪切图片 :param imgsrc: 原始图片路径(str) :param coordinate: 原始图片上的坐标(tuple) egg:(x, y, w, h) ---&gt; x,y为矩形左上角坐标, w,h为右下角坐标 :param imagPath: 剪切输出图片路径(str) :return: None &quot;&quot;&quot; image = Image.open(self.imgsrc) region = image.crop(coordinate) # 亮度增强 # region = ImageEnhance.Brightness(region).enhance(1.5) # 色度增强 # region = ImageEnhance.Color(region).enhance(1.5) # 对比度增强 # region = ImageEnhance.Contrast(region).enhance(1.5) # 锐度增强 # region = ImageEnhance.Sharpness(region).enhance(3.0) region.save(imagPath) # 图片识别 def ImagRecognition(self): # 切割掉背景图 image = Image.open(self.imgsrc) size = image.size source = self.imgsrc.split('/')[-1] box = (0, int(size[1] * 0.1), int(size[0]), int(size[1])) if not os.path.exists('./dataset/douyin_crop/' + self.date): os.mkdir('./dataset/douyin_crop/' + self.date) imagPath = './dataset/douyin_crop/' + self.date + '/' + source self.cutImg(box, imagPath) self.transfer(imagPath) # 初始化 result = self.ocr.ocr(imagPath, cls=True) image = Image.open(imagPath) size = image.size rectangle = {}.fromkeys(['抖音号', '获赞', '关注', '粉丝'], None) userInfo = {}.fromkeys(['nickName', 'userId', 'likesCount', 'fans', '本人'], None) userInfo['nickName'] = '' # 第一次遍历 for line in result: # 存抖音号及关键字坐标 if line[1][0].find('抖音号') != -1: rectangle.update({'抖音号': line[0]}) pattern = re.compile(r'[抖音号：\\u4e00-\\u9fa5]') userInfo.update({'userId': re.sub(pattern, &quot;&quot;, line[1][0])}) if line[1][0] == '获赞' and rectangle['获赞'] is None: rectangle.update({'获赞': line[0]}) if line[1][0] == '关注' and rectangle['关注'] is None: rectangle.update({'关注': line[0]}) if line[1][0] == '粉丝' and rectangle['粉丝'] is None: rectangle.update({'粉丝': line[0]}) if line[1][0].find('编辑资料') != -1 or line[1][0].find('添加朋友') != -1: userInfo.update({'本人': '是'}) # 非本人 if userInfo['本人'] is None: print('非本人主页') return None else: userInfo.pop('本人') # 未识别 if rectangle['抖音号'] is None or rectangle['获赞'] is None or rectangle['关注'] is None or rectangle['粉丝'] is None: print('未识别') return None # 第二次遍历, 根据坐标计算所需字段内容 for line in result: if line[0][0][0] &gt; rectangle['获赞'][0][0] - int(size[0] * 0.08) and line[0][1][0] &lt; int(size[0] * 0.5) \\ and line[0][3][1] &lt; rectangle['获赞'][3][1] + int(size[1] * 0.05) and line[0][0][1] &gt; rectangle['获赞'][3][1] and userInfo['likesCount'] is None: userInfo.update({'likesCount': line[1][0]}) if line[0][3][1] &lt; rectangle['粉丝'][3][1] + int(size[1] * 0.05) and line[0][0][1] &gt; rectangle['粉丝'][3][1] \\ and rectangle['粉丝'][0][0] &lt; int((line[0][0][0] + line[0][1][0]) / 2) &lt; rectangle['粉丝'][1][0] and userInfo['fans'] is None: userInfo.update({'fans': line[1][0]}) if line[0][2][1] &lt; rectangle['抖音号'][1][1] and line[0][0][1] &gt; rectangle['抖音号'][0][1] - int(size[1] * 0.07): userInfo['nickName'] += line[1][0] return userInfo api.py12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import sys, osfrom ocrAPI import ocrAPIfrom aiohttp import webasync def postOCR(request): try: try: data = await request.json() except: data = {} print('postCommodityCategory start ==&gt; {} {} {}'.format( request.url, data, request.transport.get_extra_info('peername'))) try: url = data['url'] platform = data['platform'] except: url = &quot;&quot; platform = &quot;&quot; if not data: return web.json_response({ &quot;code&quot;: -1, &quot;message&quot;: &quot;失败&quot;, &quot;data&quot;: &quot;参数不全&quot; }) usr_info = recognizer.paddleOCR(url, platform) rsp = { &quot;code&quot;: 1, &quot;message&quot;: &quot;成功&quot;, &quot;data&quot;: usr_info } return web.json_response(rsp) except Exception as e: rsp = { &quot;code&quot;: -1, &quot;message&quot;: &quot;失败&quot;, &quot;data&quot;: str(e), } print('postOCR error ==&gt; {} {}'.format( request.transport.get_extra_info('peername'), str(e))) return web.json_response(rsp)app = web.Application()app.router.add_post('/ocr', postOCR)if __name__ == '__main__': recognizer = ocrAPI() web.run_app(app, host='0.0.0.0', port=5001)","link":"/2022/01/18/PaddleOCR%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1/"},{"title":"asyncpg异步操作PostgreSql","text":"异步操作 PostgreSQL 的话，我们有两个选择，一个是 asyncpg 库，另一个是 aiopg 库。 asyncpg 是自己实现了一套连接驱动，而 aiopg 则是对 psycopg2 进行了封装，个人更推荐 asyncpg，性能和活跃度都比 aiopg 要好。 下面来看看如何使用 asyncpg，首先是安装，直接 pip install asyncpg 即可。 12345678910111213141516171819202122232425262728293031323334353637383940# --run--import asyncioimport asyncpgclass asyncHandle(): async def asyncSearch(self): sql = ''' ''' row1 = await conn.fetchrow(sql) row2 = await conn.fetch(sql) return row1, row2 async def asyncInsert(self, data): self.conn = await asyncpg.connect(host=&quot;&quot;, port=, database='', user='', password='') tasks = [] tasks.append(asyncio.get_event_loop().create_task(self.task1(data))) tasks.append(asyncio.get_event_loop().create_task(self.task2(data))) tasks.append(asyncio.get_event_loop().create_task(self.task3(data))) await asyncio.gather(*tasks) async def task1(self, data): sql = ''' ''' await self.conn.execute(sql) async def task2(self, data): sql = ''' ''' await self.conn.execute(sql) async def task3(self, data): sql = ''' ''' await self.conn.execute(sql)","link":"/2022/01/11/asyncpg%E5%BC%82%E6%AD%A5%E6%93%8D%E4%BD%9CPostgreSql/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2022/01/07/hello-world/"},{"title":"nohup 命令输出到指定文件","text":"在linux中运行命令行时，会输出一些日志信息，特别典型的是启用WebLogic命令时，输出一些信息，当启用demon模式运行时，又想收集这些信息咋办？ 解决的办法就是使用输出重定向，如下面的命令： 1nohup ./run &gt;log 2&gt;&amp;1 &amp; 其中 log是保存输出的文件名称； 2&gt;&amp;1 表示不仅命令行正常的输出保存到log中，产生错误信息的输出也保存到log文件中； &amp; 表示该进程在后台运行； nohup表示进程在当用户注销（logout）或者网络断开时不会被终止。 注意：这里若不指定输出日志文件，缺省地会输出到nohup.out文件中","link":"/2022/01/13/nohup-%E5%91%BD%E4%BB%A4%E8%BE%93%E5%87%BA%E5%88%B0%E6%8C%87%E5%AE%9A%E6%96%87%E4%BB%B6/"},{"title":"python代码优化cProfile的用法","text":"cProfile 输出profile到result.out1python -m cProfile -o result.out -s cumulative test.py 注：也可在控制台查看，删掉-o选项，也省去步骤21python3 -m cProfile -s cumulative test.py 2.result.out为二进制文件，需要再写一个python脚本查看： 123456import pstatsp=pstats.Stats('result.out')p.print_stats()p.sort_stats('calls').print_stats()p.sort_stats('cumulative').print_stats() 其中，cProfile出的各个参数： ncalls：表示函数调用的次数； tottime：表示指定函数的总的运行时间，除掉函数中调用子函数的运行时间； percall：（第一个percall）等于 tottime/ncalls； cumtime：表示该函数及其所有子函数的调用运行的时间，即函数开始调用到返回的时间； percall：（第二个percall）即函数运行一次的平均时间，等于 cumtime/ncalls； filename:lineno(function)：每个函数调用的具体信息","link":"/2022/01/07/python%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96cProfile%E7%9A%84%E7%94%A8%E6%B3%95/"},{"title":"使用scp命令实现服务器上传下载","text":"1、从服务器上下载文件 scp username@servername:/path/filename /Users/mac/Desktop（本地目录） 例如: 1scp root@115.29.175.142:/root/test.txt /Users/mac/Desktop 就是将服务器上的/root/test.txt下载到本地的/Users/mac/Desktop目录下。注意两个地址之间有空格！ 2、上传本地文件到服务器 scp /path/filename username@servername:/path 例如: 1scp /Users/mac/Desktop/test.txt root@115.29.175.142:/root/ 3、从服务器下载整个目录 scp -r username@servername:/root/（远程目录） /Users/mac/Desktop（本地目录） 例如: 1scp -r root@115.29.175.142:/root/ /Users/mac/Desktop/ 4、上传目录到服务器 scp -r local_dir username@servername:remote_dir 例如： 1scp -r test root@115.29.175.142:/root/ 把当前目录下的test目录上传到服务器的/root/ 目录 注：目标服务器要开启写入权限。","link":"/2022/01/07/%E4%BD%BF%E7%94%A8scp%E5%91%BD%E4%BB%A4%E5%AE%9E%E7%8E%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E4%BC%A0%E4%B8%8B%E8%BD%BD/"},{"title":"后台运行&#x2F;进程查看及终止","text":"后台运行 nohup 用途：不挂断地运行命令。 语法：nohup Command [ Arg … ] [ &amp; ] 无论是否将 nohup 命令的输出重定向到终端，输出都将附加到当前目录的 nohup.out 文件中。 如果当前目录的 nohup.out 文件不可写，输出重定向到 $HOME/nohup.out 文件中。 如果没有文件能创建或打开以用于追加，那么 Command 参数指定的命令不可调用。 退出状态：该命令返回下列出口值： 126 可以查找但不能调用 Command 参数指定的命令。 127 nohup 命令发生错误或不能查找由 Command 参数指定的命令。 否则，nohup 命令的退出状态是 Command 参数指定命令的退出状态。 &amp; 用途：在后台运行 一般两个一起用 nohup command &amp; eg: 12# --run--nohup python3 index.py &amp; crontab 12# --run--crontab -e crontab 文件的格式：{minute} {hour} {day-of-month} {month} {day-of-week} {full-path-to-shell-script}o minute: 区间为 0 – 59o hour: 区间为0 – 23o day-of-month: 区间为0 – 31o month: 区间为1 – 12. 1 是1月. 12是12月.o Day-of-week: 区间为0 – 7. 周日可以是0或7. Crontab 示例 在 12:01 a.m 运行，即每天凌晨过一分钟。这是一个恰当的进行备份的时间，因为此时系统负载不大。 1 0 * * * /root/bin/backup.sh 每个工作日(Mon – Fri) 11:59 p.m 都进行备份作业。 59 11 * * 1,2,3,4,5 /root/bin/backup.sh 下面例子与上面的例子效果一样： 59 11 * * 1-5 /root/bin/backup.sh 每5分钟运行一次命令 */5 * * * * /root/bin/check-status.sh 每个月的第一天 1:10 p.m 运行 10 13 1 * * /root/bin/full-backup.sh 每个工作日 11 p.m 运行。 0 23 * * 1-5 /root/bin/incremental-backup.sh Crontab 选项以下是 crontab 的有效选项: o crontab –e : 修改 crontab 文件. 如果文件不存在会自动创建。o crontab –l : 显示 crontab 文件。o crontab -r : 删除 crontab 文件。o crontab -ir : 删除 crontab 文件前提醒用户。 以上就是crontab命令的具体使用方法了。 进程查看及终止 jobs - l 12# --run--jobs -l jobs命令只看当前终端生效的，关闭终端后，在另一个终端jobs已经无法看到后台跑得程序了，此时利用ps（进程查看命令） ps -ef 12# --run--ps -aux|grep chat.js a: 显示所有程序 u: 以用户为主的格式来显示 x: 显示所有程序，不以终端机来区分 注： 用ps -def | grep查找进程很方便，最后一行总是会grep自己 用grep -v参数可以将grep命令排除掉 12# --run--ps -aux|grep chat.js| grep -v grep 再用awk提取一下进程ID 12# --run--ps -aux|grep chat.js| grep -v grep | awk '{print $2}' 如果某个进程起不来，可能是某个端口被占用 查看使用某端口的进程 123# --run--lsof -i:8090netstat -ap|grep 8090 查看到进程id之后，使用netstat命令查看其占用的端口 12# --run--netstat -nap|grep 7779 使用kill杀掉进城后再启动 终止后台运行的进程 12345# --run--kill -9 进程号pkill 进程号/进程名ps -ef | grep fileName.py | grep -v grep | cut -c 9-16 | xargs kill -9ps -aux|grep lask.py| grep -v grep | awk '{print $2}'","link":"/2022/01/07/%E5%90%8E%E5%8F%B0%E8%BF%90%E8%A1%8C-%E8%BF%9B%E7%A8%8B%E6%9F%A5%E7%9C%8B%E5%8F%8A%E7%BB%88%E6%AD%A2/"},{"title":"快速排序的四种python实现","text":"快速排序算法，简称快排，是最实用的排序算法，没有之一，各大语言标准库的排序函数也基本都是基于快排实现的。 本文用python语言介绍四种不同的快排实现。 一行代码实现的简洁版本 1quick_sort = lambda array: array if len(array) &lt;= 1 else quick_sort([item for item in array[1:] if item &lt;= array[0]]) + [array[0]] + quick_sort([item for item in array[1:] if item &gt; array[0]]) 网上常见的快排实现 12345678910111213141516def quick_sort(array, left, right): if left &gt;= right: return low = left high = right key = array[low] while left &lt; right: while left &lt; right and array[right] &gt; key: right -= 1 array[left] = array[right] while left &lt; right and array[left] &lt;= key: left += 1 array[right] = array[left] array[right] = key quick_sort(array, low, left - 1) quick_sort(array, left + 1, high) 由于快排是原地排序，因此不需要返回array。 array如果是个列表的话，可以通过len(array)求得长度，但是后边递归调用的时候必须使用分片，而分片执行的原列表的复制操作，这样就达不到原地排序的目的了，所以还是要传上边界和下边界的。 《算法导论》中的快排程序 123456789101112131415def quick_sort(array, l, r): if l &lt; r: q = partition(array, l, r) quick_sort(array, l, q - 1) quick_sort(array, q + 1, r) def partition(array, l, r): x = array[r] i = l - 1 for j in range(l, r): if array[j] &lt;= x: i += 1 array[i], array[j] = array[j], array[i] array[i + 1], array[r] = array[r], array[i+1] return i + 1 这个版本跟上个版本的不同在于分片过程不同，只用了一层循环，并且一趟就完成分片，相比之下代码要简洁的多了。 用栈实现非递归的快排程序 先说两句题外话，一般意义上的栈有两层含义，一层是后进先出的数据结构栈，一层是指函数的内存栈，归根结底，函数的内存栈的结构就是一个后进先出的栈。汇编代码中，调用一个函数的时候，修改的也是堆栈指针寄存器ESP，该寄存器保存的是函数局部栈的栈顶，另外一个寄存器EBP保存的是栈底。不知道与栈存储空间相对的堆存储空间，其组织结构是否也是一个完全二叉树呢？高级语言将递归转换为迭代，用的也是栈，需要考虑两个问题:1）栈里边保存什么？2）迭代结束的条件是什么？栈里边保存的当然是需要迭代的函数参数，结束条件也是跟需要迭代的参数有关。对于快速排序来说，迭代的参数是数组的上边界low和下边界high，迭代结束的条件是low == high。 12345678910111213141516171819def quick_sort(array, l, r): if l &gt;= r: return stack = [] stack.append(l) stack.append(r) while stack: low = stack.pop(0) high = stack.pop(0) if high - low &lt;= 0: continue x = array[high] i = low - 1 for j in range(low, high): if array[j] &lt;= x: i += 1 array[i], array[j] = array[j], array[i] array[i + 1], array[high] = array[high], array[i + 1] stack.extend([low, i, i + 2, high]) 另外，当数组下标为-1时，C++、Java等语言中会报错，但python中访问的是最后一个元素，所以如果程序写错了，可能其他语言会报错，但python会输出一个错误的结果。","link":"/2022/01/18/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E7%9A%84%E5%9B%9B%E7%A7%8Dpython%E5%AE%9E%E7%8E%B0/"},{"title":"消费Kafka同步到Hologres(一)","text":"KafkaConsumer内网连接方式：12345678from kafka import KafkaConsumerself.consumer = KafkaConsumer(bootstrap_servers=kafkaConfig['host'], group_id=kafkaConfig['groupId'], api_version=(0, 10, 2), session_timeout_ms=25000, max_poll_records=1000, fetch_max_bytes=1 * 1024 * 1024) 外网连接方式：123456789101112from kafka import KafkaConsumerself.consumer = KafkaConsumer(bootstrap_servers=kafkaConfig['bootstrap_servers'], group_id=consumer_id, sasl_mechanism=&quot;PLAIN&quot;, ssl_context=context, security_protocol='SASL_SSL', api_version=(0, 10), sasl_plain_username=kafkaConfig['sasl_plain_username'], sasl_plain_password=kafkaConfig['sasl_plain_password'], session_timeout_ms=25000, max_poll_records=10) Offsetkafka高吞吐量的保证是Partition是顺序写磁盘，同样消费也是顺序的，offset维护了一个group的消费者在当前partition消费的数据位置。 当一个consumer启动后，会查询服务端的offset作为本地offset 运行中poll数据使用的是本地offset，不再查询server 每poll完一批数据，自动更新本地offset server端也会维护一个offset，新版kafka offset是维护在一个topic中，旧版维护在zookeeper 提交offset是指：使用本地的offset/指定的offset 去更新server端的offset，但是本地offset不会改变 自动提交自动提交策略下，是每隔指定时间，由kafka-clients自动提交本地维护的offset，默认本地offset=poll的数量+1。（本地offset可以通过seek方法修改） 但是会出现数据丢失的情况，比如poll了一批数据没有处理完，但是到时间了已经提交了offset，然后程序终止了，下次启动会从新的offset’启动，没有处理的数据丢失了。 123self.enable_auto_commit=True,self.auto_commit_interval_ms=1000,self.consumer_timeout_ms=2000, 手动提交 不指定offset：同上，也是提交本地维护的offset，默认本地offset=poll的数量+1。 这种模式下，数据处理完毕（保存/丢弃）后再手动提交，解决了自动模式下的数据丢失问题，但是可能存在消费完的数据，offset没有提交成功，重复消费数据的问题（可以通过数据库事务解决）。 指定offset：更新server端offset为指定值，但是本地offset不会更新，所以在consumer没有重启的情况下，是不会消费到重复数据。 12self.enable_auto_commit=False, # 关闭自动提交self.consumer_timeout_ms=2000, 1234# 获取当前偏移量now_offset = message.offset # 提交偏移量，now_offset+1的原因是因为我发现如果不加1，下次消费会从上次消费最后一条数据开始，重复消费self.consumer.commit(offsets={tp:(OffsetAndMetadata(now_offset+1, None))}) 消费方式Kafka消费有两种指定topic的方式：subscribe和assign，两种方式主要区别在于partition的分配，前者是由kafka-clients分配的（高级消费），而后者是我们手动指定的（低级消费）。 注意：Consumer线程不安全，不能多线程共用。 高级消费对应于KafkaConsumer.subscribe()方法 12# self.consumer.subscribe([confKafka['topic_name']])self.consumer.subscribe([confKafka['topic_name']]) 使用高级消费时，假定，1-N个consumer，属于同一个group。根据订阅的consumer的个数，由kafka-clinets根据指定的分配策略分配每个consumer消费的partition。注意：必须使用合理的分配策略，否则可能出现一些consumer没有分配partition的情况。 若N&gt;partition num(所有topic的partition总和), 则一些consumer不会被分配partition 若N&lt;partition num,则某些consumer会消费多个partition 当消费多个partition时，消费每个分区内的消息是有序的，但消费多个分区之间的消息是无序的（可以在消费记录中获得当前记录的partition） partition分配策略 range: 得到topic-partitions关系，得到topic-consumers关系，然后，按照topic进行分配，即topic的所有partition按顺序分配到其所有的consumer上，举例：topicA-3partition, topicB-1partition, 4 consumers, 过程是，A的3个partition分配到consumer1-3，B的1个partition分配到consumer1，consumer4空闲，所以使用的最大线程数=max(topic*partition) roundrobin：topics和patition组合，上述例子，就是ta-0,ta-1,ta-2,tb-0,然后四个取hashcode得到顺序，然后挨个分配到consumer上（要求：每一个consumer消费的topics有相同的streams&amp;&amp;这个消费组中每个consumer消费的topics必须完全相同） Reblance订阅模式下，每加入或者离开一个consumer，都会触发consumer reblance，重新为每个消费者分配partition。 reblance的过程发生了什么？查看kafka-clients源码可以发现： AbstractCoordinator 有详细说明调用subscribe方法发生了以下的事请 consumer注册到到服务端 coordinator（server端维护的一个服务）查找所有的该组consumer，选取leander 如果auto commit为true，所有的consumer提交本地offset到服务端；为false则不提交 leader通过coordinator获取服务端所有的partition和offset，并使用策略重新分配partition，结果返回给coordinator，coordinator下发分配结果到所有consumer（即jon和leave的reblance）。 所以高级消费者集群时，新加入的consumer，如果是auto-commit则会提交offset，若未处理完可能会丢失数据；否则不提交，会重复消费数据。离开consumer，若未提交offset离开，则会重复消费数据；若自动提交了但是未消费，则会丢失数据。 低级消费对应于KafkaConsumer.assign()方法，指定TopicPartition的集合 12self.partition = TopicPartition(topic=myTopic, partition=myPartition)self.consumer.assign([self.partition]) 使用低级消费时，直接指定consumer消费某个topic的某个partition，不再由kafka-clients分配，这种情况下，是可以多个同组消费者消费同一个partition的。 所以当同一个消费组指定重复的partition时，会消费到重复的数据(完全重复的数据，因为poll的offset是本地维护的)，但是server端只有一个offset！server的offset被两个consumer更新，会出现冲突和错乱，这种模式下，需要开发者自己保证同一个消费组的消费着具有不重复的partition。 高级or低级？如何抉择，主要取决于复杂性和数据一致性的取舍，即reblance带来的影响和手动分配带来的复杂的取舍。 数据丢失/重复消费 高级消费partition的分配是由kafka-clinets完成的，但是会查询server端的信息，所以集群环境下，当没有指定partition时，每加入/离开一个消费者，kafka-clients都会重新平衡partition的分配，这个时候，如果有消费完成但是没有提交的offset，reblance时则会造成数据的重复消费或者数据丢失（具体是哪种情况，要看offset的提交策略）。低级消费则不会发生reblance！ 注意 ：Spring-kafka多线程消费的配置下，指定topic和partition时，也是低级消费，其线程和partition的分配策略见后续spring-kafka的教程。 reblance影响性能 每次reblance都要重新分配，如果partition比较多的情况下，重新分配将会消耗大量的时间。 低级消费时的高可用 如果使用低级消费，当一个consumer退出时，其partition不会再分配给其他消费者，数据将会堆积在kafka中！所以务必要保证退出的消费者能重新运行。","link":"/2022/01/08/%E6%B6%88%E8%B4%B9Kafka%E5%90%8C%E6%AD%A5%E5%88%B0Hologres-%E4%B8%80/"},{"title":"消费Kafka同步到Hologres(三)","text":"Redis缓存机制Redis是一款内存高速缓存数据库； 数据模型为：key - value，非关系型数据库使用的存储数据的格式。 123456# Redis连接self.re_queue = redis.StrictRedis(host=confRedis['host'], port=confRedis['port'], password=confRedis['passwd'], db=confRedis['db'], decode_responses=True) 123456# Redis连接池self.pool = redis.ConnectionPool(host=self.db['host'], port=self.db['port'], db=self.db['db'], password=self.db['passwd'])self.re_queue = redis.Redis(connection_pool=self.pool) String（字符串）string 是 redis 最基本的类型，你可以理解成与 Memcached 一模一样的类型，一个 key 对应一个 value。 string 类型是二进制安全的。意思是 redis 的 string 可以包含任何数据。比如jpg图片或者序列化的对象。 string 类型是 Redis 最基本的数据类型，string 类型的值最大能存储 512MB。 1234567# outputself.re_queue.set(keyName,data)self.re_queue.setex(keyName, time, data)self.re_queue.mset()# inputresult = self.re_queue.get(keyName) Hash（哈希）Redis hash 是一个键值(key=&gt;value)对集合。 Redis hash 是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象。 1234567# outputself.re_queue.hset(name, key, value)self.re_queue.expire(name, time)# inputresult = self.re_queue.hget(name, key)result = self.re_queue.hvals(name) List（列表）Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。 1 Set（集合）Redis的Set是string类型的无序集合。 集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。 1","link":"/2022/01/08/%E6%B6%88%E8%B4%B9Kafka%E5%90%8C%E6%AD%A5%E5%88%B0Hologres-%E4%B8%89/"},{"title":"消费Kafka同步到Hologres(二)","text":"上一篇文章讲了如何用Python消费Kafka。但如果Kafka生产速度太快，而客户端消费速度跟不上的话，就需要考虑并发消费。 多进程消费业务中Kafka的topic有12个分区，QPS4000+，Hologres I/O消费速度还是跟不上。 123456import multiprocessingfrom multiprocessing import Processfor i in range(12): p = Process(target=threadTask, name='进程%d' % i) p.start() 协程消费每个进程调用协程消费。协程本质上就是一个线程，以前线程任务的切换是由操作系统控制的，遇到I/O自动切换，现在我们用协程的目的就是较少操作系统切换的开销（开关线程，创建寄存器、堆栈等，在他们之间进行切换等），在我们自己的程序里面来控制任务的切换。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374'''1、协程： 单线程实现并发 在应用程序里控制多个任务的切换+保存状态 优点： 应用程序级别速度要远远高于操作系统的切换 缺点： - 每个协程任务都会占用一个连接数，如果生产速度过快，连接数会一直增加。 - 多个任务一旦有一个阻塞没有切，整个线程都阻塞在原地 该线程内的其他的任务都不能执行了 一旦引入协程，就需要检测单线程下所有的IO行为, 实现遇到IO就切换,少一个都不行，以为一旦一个任务阻塞了，整个线程就阻塞了， 其他的任务即便是可以计算，但是也无法运行了2、协程序的目的： 想要在单线程下实现并发 并发指的是多个任务看起来是同时运行的 并发=切换+保存状态'''import timeimport asyncioimport queueimport threadingimport uuidimport random'''基于协程的消费者模型，多个协程充当worker消费消息。'''now = lambda : time.time()async def customer(num,q): print('任务 %d：start worker...' % num) while True: try: start = now() task = q.get(block=False) print('任务 %d：customer %s' % (num, task)) await asyncio.sleep(10) # 假设每个消费者消费消息需要10秒，这样可以看出生产者生成的消息被不同的消费者消费 except Exception as e: await asyncio.sleep(1) continueasync def run_async_customer(q): tasks = [] for num in range(3): tasks.append(asyncio.create_task(customer(num,q))) await asyncio.gather(*tasks)def product(q): print('product start...') while True: pro = '产品 %s' % str(uuid.uuid1()) print(pro) q.put(pro) time.sleep(random.randint(2,4))def run(q): asyncio.run(run_async_customer(q))if __name__ == '__main__': q = queue.Queue() # 开启一个线程运行生产者 prod = threading.Thread(target=product, args=(q,)) # 开启一个线程运行所有的消费者 cust = threading.Thread(target=run, args=(q,)) prod.start() cust.start() prod.join() cust.join()","link":"/2022/01/08/%E6%B6%88%E8%B4%B9Kafka%E5%90%8C%E6%AD%A5%E5%88%B0Hologres-%E4%BA%8C/"},{"title":"消费Kafka同步到Hologres(四)","text":"数据流向线程一消费Kafka topic_01消息，整理计算后存入Redis，并写入全局共享队列。 线程二读取队列中的数据写入Kafka topic_02。 通过集成资源组同步Kafka topic_02到Hologres。 跨模块全局变量管理123456789101112131415161718192021222324252627import queue# Queuedef init(): global _global_queue _global_queue = queue.Queue(maxsize=0)def put(value): _global_queue.put(value)def get(defValue=None): try: return _global_queue.get() except: return defValuedef getSize(): return _global_queue.qsize()def taskDone(): _global_queue.task_done() KafkaProducer1234567891011121314151617181920212223import golfrom kafka import KafkaProducerfrom kafka.errors import KafkaErrordef kafkaProducer(): confKafka = setting.kafkaSetting producer = KafkaProducer(bootstrap_servers=confKafka['bootstrap_servers'], api_version=(0, 10), retries=5) while True: data = gol.get() if data is None: continue gol.taskDone() key = (str(importData['uid']) + str(importData['itemId'])).encode() value = json.dumps(data).encode() try: future = producer.send(confKafka['topic_name'], key=key, value=value) future.get() except KafkaError as e: print(e)","link":"/2022/01/08/%E6%B6%88%E8%B4%B9Kafka%E5%90%8C%E6%AD%A5%E5%88%B0Hologres-%E5%9B%9B/"}],"tags":[{"name":"Kafka","slug":"Kafka","link":"/tags/Kafka/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"Mysql","slug":"Mysql","link":"/tags/Mysql/"},{"name":"Ocr","slug":"Ocr","link":"/tags/Ocr/"},{"name":"PostgreSql","slug":"PostgreSql","link":"/tags/PostgreSql/"},{"name":"Algorithm","slug":"Algorithm","link":"/tags/Algorithm/"},{"name":"Redis","slug":"Redis","link":"/tags/Redis/"},{"name":"Hologres","slug":"Hologres","link":"/tags/Hologres/"}],"categories":[{"name":"笔记","slug":"笔记","link":"/categories/%E7%AC%94%E8%AE%B0/"},{"name":"工作","slug":"工作","link":"/categories/%E5%B7%A5%E4%BD%9C/"}]}